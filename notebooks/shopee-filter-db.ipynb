{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd ../../.."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# filter all sample that doesn't have image exist on disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/shopee/database.txt', nrows=None, header=None, sep=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[0].str[18:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check = '/media/saplab/Data_Win/RSI_Do_An/AnhND/Dynamic-Crawler-Tool/output' + df[0].str[18:]\n",
    "check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if file exists\n",
    "import os\n",
    "\n",
    "# for i in check:\n",
    "#     if not os.path.isfile(i):\n",
    "#         print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = check.progress_apply(lambda x: os.path.isfile(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered = check[mask]\n",
    "filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "not_exist = check[~mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "not_exist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[filtered.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_db = df.loc[filtered.index]\n",
    "new_db[0] = filtered\n",
    "new_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shutil.which('file')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image\n",
    "import shutil\n",
    "\n",
    "#  mixed png, jpg, jpeg, webp, etc files. All files have been accidental renamed\n",
    "#  to .jpeg. Rename them back to their original extension\n",
    "\n",
    "def rename_path_to_original_extension(img_path):\n",
    "    try:\n",
    "        with Image.open(img_path) as img:\n",
    "            img.verify()\n",
    "            image_format = img.format.lower()\n",
    "            new_filename = img_path.replace('.jpeg', f'.{image_format}')\n",
    "            # os.rename(img_path, new_filename)\n",
    "            shutil.move(img_path, new_filename)\n",
    "            return new_filename\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_db[0] = new_db[0].progress_apply(rename_path_to_original_extension)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extension = new_db[0].str.split('.').str[-1]\n",
    "extension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_db.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_db[0] = 'data/shopee' + new_db[0].str[59:]\n",
    "new_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_db.to_csv('./data/shopee/database-filtered2.txt', header=None, index=None, sep=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = new_db.sample(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.to_csv('./data/shopee/test2.txt', header=None, index=None, sep=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!du -shc data/shopee/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wc -l data/shopee/*"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd /home/saplab/thaiminhpv/relahash/rsi-prototype/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.jit.load('./torchsripts_models/orthocos_tf_efficientnetv2_b3_orthohash_64_deepfashion2_200_0.pt', map_location=torch.device('cuda:0'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.train_helper import prepare_dataloader, prepare_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('logs/orthocos_mobilenetv3small_orthohash_3072_shopee_5_0.0001_adam/001_few_shot_orthohash_3072bit_32_s_500/config.json', 'r') as f:\n",
    "    config = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config['batch_size'] = 512\n",
    "config['max_batch_size'] = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, db_loader = prepare_dataloader(config, include_train=False)[1:]  # test, database loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import cv2\n",
    "# def get_hash(img):\n",
    "#     img = cv2.resize(img, (256, 256))\n",
    "#     img = torch.from_numpy(img).permute(2, 0, 1).unsqueeze(0).float().cuda()\n",
    "#     codes = model(img)\n",
    "#     codes = convert_int(codes)\n",
    "#     return codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_codes(model, test_loader, device):\n",
    "    model.eval()\n",
    "\n",
    "    ret_codes = []\n",
    "    ret_labels = []\n",
    "\n",
    "    pbar = tqdm(test_loader, desc='Test', ascii=True, bar_format='{l_bar}{bar:10}{r_bar}')\n",
    "    for i, (data, labels, index) in enumerate(pbar):\n",
    "        with torch.no_grad():\n",
    "            data, labels = data.to(device), labels.to(device)\n",
    "            code_logits = model(data)[1]  # code logits always at position 1\n",
    "\n",
    "            ret_codes.append(code_logits.cpu())\n",
    "            ret_labels.append(labels.cpu())\n",
    "        # if i == 5:\n",
    "            # break\n",
    "\n",
    "    res = {\n",
    "        'codes': torch.cat(ret_codes),\n",
    "        'labels': torch.cat(ret_labels)\n",
    "    }\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_loader.dataset.get_img_paths()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# db_out = get_codes(model, db_loader, 'cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(db_out, 'db_out.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = next(iter(db_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = sample[0].permute(0,2,3,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = a.int()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.imshow(b[11])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(b[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd /home/saplab/thaiminhpv/relahash/rsi-prototype/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import json\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = torch.jit.load('./torchsripts_models/orthocos_tf_efficientnetv2_b3_orthohash_64_deepfashion2_200_0.pt', map_location=torch.device('cuda:0'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self,\n",
    "            filename: str,\n",
    "            transform=None,\n",
    "            target_transform=None,\n",
    "        ) -> None:\n",
    "        super().__init__()\n",
    "        self.loader = lambda x: cv2.cvtColor(cv2.imread(x), cv2.COLOR_BGR2RGB)\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "        self.train_data = []\n",
    "        self.train_labels = []\n",
    "        with open(filename, 'r') as f:\n",
    "            while True:\n",
    "                lines = f.readline()\n",
    "                if not lines:\n",
    "                    break\n",
    "\n",
    "                path_tmp = lines.split()[0]\n",
    "                label_tmp = lines.split()[1:]\n",
    "                self.is_onehot = len(label_tmp) != 1\n",
    "                if not self.is_onehot:\n",
    "                    label_tmp = lines.split()[1]\n",
    "                    self.max_index = 110434  # shopee num ID\n",
    "\n",
    "                self.train_data.append(path_tmp)\n",
    "                self.train_labels.append(label_tmp)\n",
    "\n",
    "                is_pkl = path_tmp.endswith('.pkl')  # if save as pkl, pls make sure dont use different style of loading\n",
    "\n",
    "        self.train_data = np.array(self.train_data)\n",
    "        self.train_labels = np.array(self.train_labels, dtype=float)\n",
    "\n",
    "    def to_onehot(self, i):\n",
    "        t = torch.zeros(self.max_index)\n",
    "        t[i] = 1\n",
    "        return t\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        img, target = self.train_data[index], self.train_labels[index]\n",
    "        if not self.is_onehot:\n",
    "            target = self.to_onehot(target.astype(int))\n",
    "\n",
    "        try:\n",
    "            img = self.loader(img)\n",
    "        except Exception as e:\n",
    "            # logging.exception(e)\n",
    "            print(e)\n",
    "            print(f\"==| Corrupted sample |=='{img}'\")\n",
    "            return None, None, None\n",
    "\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(image=img)['image'].float()\n",
    "\n",
    "        if self.target_transform is not None:\n",
    "            target = self.target_transform(target)\n",
    "\n",
    "        return img, target, index\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.train_data)\n",
    "\n",
    "    def get_img_paths(self):\n",
    "        return self.train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = CustomDataset('./data/shopee/database.txt', transform=A.Compose([\n",
    "    A.Resize(224, 224),\n",
    "    ToTensorV2()\n",
    "]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(dataset, batch_size=128, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def convert_int(codes):\n",
    "    out = codes.sign().cpu().numpy().astype(int)\n",
    "    out[out == -1] = 0\n",
    "    out = np.packbits(out, axis=-1)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_code = []\n",
    "output_label = []\n",
    "output_index = []\n",
    "with torch.no_grad():\n",
    "    for data, labels, index in dataloader:\n",
    "        if data is None:\n",
    "            continue\n",
    "        data, labels = data.cuda(), labels.cuda()\n",
    "        code_logits = model(data)\n",
    "        codes = convert_int(code_logits)\n",
    "        _labels = labels.argmax(dim=-1).cpu().numpy()\n",
    "        # output.append((codes, _labels, index.cpu().numpy()))\n",
    "        output_code.append(codes)\n",
    "        output_label.append(_labels)\n",
    "        output_index.append(index.cpu().numpy())\n",
    "        # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "codes = np.concatenate(output_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.concatenate(output_label)\n",
    "# labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = np.concatenate(output_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({\n",
    "    'codes': codes,\n",
    "    'labels': labels,\n",
    "    'index': index\n",
    "}, 'db_out.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thaiminhpv-3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
